{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from dataloader.dataset import ImageLoader_synthtext, collate\n",
    "from utils import averager\n",
    "from craft import CRAFT\n",
    "\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from multiprocessing import set_start_method\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
    "\n",
    "## 월드 사이즈는 1 랭크는 0\n",
    "# workers =4\n",
    "# epochs = 90\n",
    "# batch-size = 8\n",
    "# world-size = 1\n",
    "# rank = 0\n",
    "# dist-backend = \"ncll\"\n",
    "# gpu_count = 4\n",
    "# url = 'tcp://127.0.0.1:2222'\n",
    "# distributed = True\n",
    "# ngpus_per_node = 4\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='SynthText')\n",
    "parser.add_argument('--img_rootdir', default='/data/data/synthtext/SynthText/', type=str)\n",
    "parser.add_argument('--gt_mat', default='/data/data/synthtext/SynthText/gt.mat', type=str)\n",
    "parser.add_argument('--batch_size', type=int, default=48, help='input batch size')\n",
    "parser.add_argument('--store_sample', default='store', help='Where to store samples')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate for critic')\n",
    "parser.add_argument('--epoch', type=int, default=10, help='number of epochs to train for')\n",
    "parser.add_argument('--displayInterval', type=int, default=20, help='Interval to be displayed')\n",
    "parser.add_argument('--saveInterval', type=int, default=2000, help='Interval to be displayed')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--gpu', default='1,2,3,4', help='')\n",
    "parser.add_argument('--gpu_count', type=int, default=4, help='')\n",
    "parser.add_argument('--world_size', type=int, default=1, help='')\n",
    "parser.add_argument('--rank', type=int, default=0, help='')\n",
    "parser.add_argument('--workers', type=int, default=16, help='')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_acc1 = 0\n",
    "def main():\n",
    "    ngpus_per_node = args.gpu_count\n",
    "    args.world_size = ngpus_per_node * args.world_size\n",
    "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "    \n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp \n",
    "\n",
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "    \n",
    "    args.gpu = gpu\n",
    "    \n",
    "    print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "    args.rank = args.rank * ngpus_per_node + gpu\n",
    "    \n",
    "    ## 워커초기화\n",
    "    dist.init_process_group(backend=\"nccl\", init_method=\"tcp://127.0.0.1:2222\",world_size=args.world_size, rank=args.rank)\n",
    "    \n",
    "    craft = CRAFT()\n",
    "    criterion = torch.nn.MSELoss(reduction='mean').cuda(args.gpu)\n",
    "    optimizer = optim.Adam(craft.parameters(), lr=args.lr)\n",
    "\n",
    "    craft.cuda(args.gpu)\n",
    "    craft = torch.nn.parallel.DistributedDataParallel(craft, device_ids=[args.gpu])\n",
    "#     num_params = sum(p.numel() for p in craft.parameters() if p.requires_grad)\n",
    "    ## 모델 선언 끝\n",
    "    \n",
    "    \n",
    "    ## 데이터 셋 선언\n",
    "    print(args.gpu,\"번째 데이터 로드 시작\")\n",
    "  \n",
    "    args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "    args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
    "    print(args.gpu,\"번째 배치사이즈: \",args.batch_size,\" 일하는 woker : \",args.workers)\n",
    "    \n",
    "    dataset = ImageLoader_synthtext(args)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset,batch_size=args.batch_size,num_workers=args.workers, pin_memory=True,sampler=train_sampler)\n",
    "    print(args.gpu,\"번째 데이터 로드 끝\")\n",
    "    \n",
    "    ## 데이터셋 선언 끝\n",
    "    \n",
    "    \n",
    "    ''' -------------------------logger 선언----------------------------'''\n",
    "    train_logger = util.Logger(os.path.join(save_path, './train.log'))\n",
    "    valid_logger = util.Logger(os.path.join(save_path, './valid.log'))\n",
    "    train_time_logger = util.Logger(os.path.join(save_path, './train_time.log'))\n",
    "    valid_time_logger = util.Logger(os.path.join(save_path, './valid_time.log'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## 학습 시작\n",
    "    args.start_epoch = 0\n",
    "    for epoch in range(args.start_epoch, args.epoch):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        train(train_loader, model, criterion, optimizer, epoch, args, train_logger,train_time_logger)\n",
    "        \n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "    \n",
    "    \n",
    "    \n",
    "def train(train_loader, model, criterion, optimizer, epoch, args, logger, time_logger):\n",
    "    ''' -------------------------averageMeter 선언.-----------------------------'''\n",
    "    batch_time = util.AverageMeter('Time', ':6.3f')\n",
    "    data_time = util.AverageMeter('Data', ':6.3f')\n",
    "    losses = util.AverageMeter('Loss', ':.4f')\n",
    "\n",
    "    ''' -------------------------출력 progress 선언.-----------------------------'''\n",
    "    progress = util.ProgressMeter(len(train_loader),[batch_time, data_time, losses],prefix=\"Epoch: [{}]\".format(epoch))\n",
    "    \n",
    "    \n",
    "    ''' -------------------------학습 시작.-----------------------------'''\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        \n",
    "        img, char_label, interval_label = data\n",
    "        \n",
    "        img = img.cuda(args.gpu, non_blocking=True)\n",
    "        char_label = char_label.cuda(args.gpu, non_blocking=True)\n",
    "        interval_label = interval_label.cuda(args.gpu, non_blocking=True)\n",
    "        \n",
    "        \n",
    "        img.requires_grad_()\n",
    "        optimizer.zero_grad()\n",
    "        preds, _ = craft(img)\n",
    "        cost_char = criterion(preds[:,:,:,0], char_label).sum()/div\n",
    "        cost_interval = criterion(preds[:,:,:,1], interval_label).sum()/div\n",
    "        cost = cost_char + cost_interval\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_gradients(craft)\n",
    "        \n",
    "        \n",
    "        if dist.get_rank() == 0:\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "                \n",
    "    if dist.get_rank() == 0:\n",
    "        logger.write([epoch, losses.avg])\n",
    "        time_logger.write([epoch, batch_time.avg, data_time.avg])\n",
    "        \n",
    "def average_gradients(model):\n",
    "    for param in model.parameters():\n",
    "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM)\n",
    "        param.grad.data /= args.gpu_count\n",
    "        \n",
    "def reduce_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    # gpu 갯수로 나눠줌.\n",
    "    rt /= args.gpu_count\n",
    "    return rt\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
