{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b81687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-4f8c8309-37ce-4677-88bf-3a4c74293690.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from dataloader.dataset import ImageLoader_synthtext, collate\n",
    "from utils import averager\n",
    "from craft import CRAFT\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='SynthText')\n",
    "parser.add_argument('--img_rootdir', default='/data/data/synthtext/SynthText/', type=str)\n",
    "parser.add_argument('--gt_mat', default='/data/data/synthtext/SynthText/gt.mat', type=str)\n",
    "parser.add_argument('--go_on', default='', type=str)\n",
    "parser.add_argument('--pre_model', default='', type=str)\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='input batch size')\n",
    "parser.add_argument('--store_sample', default='store', help='Where to store samples')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate for critic')\n",
    "parser.add_argument('--epoch', type=int, default=10, help='number of epochs to train for')\n",
    "parser.add_argument('--displayInterval', type=int, default=20, help='Interval to be displayed')\n",
    "parser.add_argument('--saveInterval', type=int, default=2000, help='Interval to be displayed')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if not os.path.isdir(args.store_sample):\n",
    "    os.system('mkdir {0}'.format(args.store_sample))\n",
    "\n",
    "## 찍어보기 위한 용도\n",
    "eval_saveimg_target_dir = \"./es_img/\"\n",
    "target_img_path = \"./picture/pic1.jpg\"\n",
    "target_img = cv2.imread(target_img_path)\n",
    "target_img = cv2.resize(target_img, (2240, 1260))\n",
    "target_img = torch.FloatTensor(target_img).cuda().permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "print(\"데이터 로드 시작\")\n",
    "\n",
    "dataset = ImageLoader_synthtext(args)\n",
    "assert dataset\n",
    "data_loader = torch.utils.data.DataLoader(dataset, args.batch_size, num_workers=0, shuffle=True, collate_fn=collate)\n",
    "\n",
    "print(\"데이터 로드 끝\")\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "criterion = criterion.cuda()\n",
    "craft = CRAFT(pretrained=True)\n",
    "\n",
    "# craft=craft.cuda()\n",
    "\n",
    "print(\"모델 생성 끝\")\n",
    "\n",
    "if args.go_on != '':\n",
    "    print('loading pretrained model from %s' % args.pre_model)\n",
    "    craft.load_state_dict(torch.load(args.pre_model), strict=False)\n",
    "\n",
    "craft = torch.nn.DataParallel(craft)\n",
    "craft = craft.cuda()\n",
    "\n",
    "loss_avg = averager()\n",
    "optimizer = optim.Adam(craft.parameters(), lr=args.lr)\n",
    "\n",
    "print(\"옵티마이저 선언 끝\")\n",
    "\n",
    "def train_batch(data):\n",
    "    div = 10\n",
    "    craft.train()\n",
    "    img, char_label, interval_label = data\n",
    "    img = img.cuda()\n",
    "    char_label = char_label.cuda()\n",
    "    interval_label = interval_label.cuda()\n",
    "\n",
    "    img.requires_grad_()\n",
    "    optimizer.zero_grad()\n",
    "    preds, _ = craft(img)\n",
    "    cost_char = criterion(preds[:,:,:,0], char_label).sum()/div\n",
    "    cost_interval = criterion(preds[:,:,:,1], interval_label).sum()/div\n",
    "    cost = cost_char + cost_interval\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    return cost\n",
    "\n",
    "def main():    \n",
    "    count = 0\n",
    "    for epoch in range(args.epoch):\n",
    "        print(epoch,\"시작\")\n",
    "        train_iter = iter(data_loader)\n",
    "        i = 0\n",
    "        while i < len(data_loader):\n",
    "            time0 = time.time()\n",
    "            data = train_iter.next()\n",
    "            cost = train_batch(data)\n",
    "            loss_avg.add(cost)\n",
    "            i += 1\n",
    "\n",
    "            # do checkpointing\n",
    "            if i % args.saveInterval == 0:\n",
    "                torch.save(craft.state_dict(), '{0}/craft_{1}_{2}_{3}.pth'.format(args.store_sample, epoch, i, loss_avg.val()))\n",
    "\n",
    "            if i % args.displayInterval == 0:\n",
    "                \n",
    "                craft.eval()\n",
    "                output, _ = craft(target_img)\n",
    "                char_label = output[:,:,:,0].squeeze()\n",
    "                char_label = char_label.cpu().detach().numpy()\n",
    "                char_label = np.clip(char_label, 0, 255).astype(np.uint8)\n",
    "                char_label = cv2.applyColorMap(char_label, cv2.COLORMAP_JET)\n",
    "                cv2.imwrite(eval_saveimg_target_dir+str(count)+'_iter_'+str(i)+'.jpg', char_label)\n",
    "                count = count+1\n",
    "                craft.train()\n",
    "                \n",
    "                \n",
    "                print('[%d/%d][%d/%d] lr: %.4f Loss: %f Time: %f s' %\n",
    "                    (epoch, args.epoch, i, len(data_loader), optimizer.param_groups[0]['lr'], loss_avg.val(), time.time()-time0))\n",
    "                loss_avg.reset()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b239f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel import DataParallelCriterion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
